{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skashyap777/Digifoxintern/blob/main/ReDEPLOY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "3_4ulLfbuzCU",
        "outputId": "86e98d01-580b-436e-c098-ae2135fc0225"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b836b439-78f5-4f1c-b9b4-7c0f184f4715\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b836b439-78f5-4f1c-b9b4-7c0f184f4715\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving label_encoders.pkl to label_encoders.pkl\n",
            "Saving feature_modes.pkl to feature_modes.pkl\n",
            "Saving feature_names.txt to feature_names.txt\n",
            "Saving rf_model.pkl to rf_model.pkl\n",
            "Saving selected_features.pkl to selected_features.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --ignore-installed blinker"
      ],
      "metadata": {
        "id": "uR4bA5_v2Hm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b448b4-8c98-4a60-a9d3-74d9af279028"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blinker\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: blinker\n",
            "Successfully installed blinker-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -g localtunnel\n",
        "!pip install -q joblib pandas numpy scikit-learn"
      ],
      "metadata": {
        "id": "3jGip_RivF4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27afbd1-4f0c-4d8a-edd8-5158c5baa50f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Gene Mutation Pathogenicity Predictor\",\n",
        "    page_icon=\"üß¨\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 3rem;\n",
        "        color: #2E8B57;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.5rem;\n",
        "        color: #4682B4;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .feature-section {\n",
        "        background-color: #f0f2f6;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .prediction-result {\n",
        "        font-size: 2rem;\n",
        "        text-align: center;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .pathogenic {\n",
        "        background-color: #ffebee;\n",
        "        color: #c62828;\n",
        "        border: 2px solid #ef5350;\n",
        "    }\n",
        "    .benign {\n",
        "        background-color: #e8f5e8;\n",
        "        color: #2e7d32;\n",
        "        border: 2px solid #66bb6a;\n",
        "    }\n",
        "    .upload-section {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 2rem;\n",
        "        border-radius: 1rem;\n",
        "        margin: 1rem 0;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .upload-section h3 {\n",
        "        color: white;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .file-upload-info {\n",
        "        background-color: #e3f2fd;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 4px solid #2196f3;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load model and preprocessing objects\n",
        "@st.cache_resource\n",
        "def load_model_artifacts():\n",
        "    try:\n",
        "        model = joblib.load('rf_model.pkl')\n",
        "        with open('selected_features.pkl', 'rb') as f:\n",
        "            selected_features = pickle.load(f)\n",
        "        with open('label_encoders.pkl', 'rb') as f:\n",
        "            label_encoders = pickle.load(f)\n",
        "        with open('feature_modes.pkl', 'rb') as f:\n",
        "            feature_modes = pickle.load(f)\n",
        "        st.info(\"Model and artifacts loaded successfully.\")\n",
        "        return model, selected_features, label_encoders, feature_modes\n",
        "    except FileNotFoundError as e:\n",
        "        st.error(f\"File not found: {e}. Please upload rf_model.pkl, selected_features.pkl, label_encoders.pkl, and feature_modes.pkl to the Colab /content/ directory.\")\n",
        "        return None, None, None, None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading artifacts: {e}. Check library versions (pandas==2.2.2, scikit-learn==1.5.2, joblib==1.4.2).\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    st.markdown('<h1 class=\"main-header\">üß¨ Gene Mutation Pathogenicity Predictor</h1>', unsafe_allow_html=True)\n",
        "\n",
        "    # Load model artifacts\n",
        "    model, selected_features, label_encoders, feature_modes = load_model_artifacts()\n",
        "\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    st.markdown(\"### Predict whether a gene mutation is **Pathogenic** or **Benign**\")\n",
        "\n",
        "    # Add prominent CSV upload section at the top\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"upload-section\">\n",
        "        <h3>üìÅ Quick CSV Upload for Batch Predictions</h3>\n",
        "        <p>Upload your gene mutation CSV file to get instant pathogenicity predictions for multiple mutations!</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # CSV Upload section\n",
        "    with st.expander(\"üöÄ **UPLOAD CSV FILE FOR BATCH PREDICTIONS**\", expanded=True):\n",
        "        csv_upload_section(model, selected_features, label_encoders, feature_modes)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Sidebar for navigation\n",
        "    st.sidebar.title(\"Navigation\")\n",
        "    page = st.sidebar.selectbox(\"Choose a page:\", [\"Single Prediction\", \"Advanced Batch Upload\", \"Feature Information\", \"CSV Format Guide\"])\n",
        "\n",
        "    if page == \"Single Prediction\":\n",
        "        single_prediction_page(model, selected_features, label_encoders, feature_modes)\n",
        "    elif page == \"Advanced Batch Upload\":\n",
        "        batch_prediction_page(model, selected_features, label_encoders, feature_modes)\n",
        "    elif page == \"CSV Format Guide\":\n",
        "        csv_format_guide_page(selected_features, label_encoders, feature_modes)\n",
        "    else:\n",
        "        feature_information_page(selected_features)\n",
        "\n",
        "def csv_upload_section(model, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Quick CSV upload section for the main page\"\"\"\n",
        "    st.markdown(\"**Upload your CSV file with gene mutation data:**\")\n",
        "\n",
        "    # File upload\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Choose a CSV file\",\n",
        "        type=\"csv\",\n",
        "        help=\"Upload a CSV file containing gene mutation data. Ensure columns match the model features.\"\n",
        "    )\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            st.success(f\"‚úÖ File uploaded successfully! {df.shape[0]} mutations found in {df.shape[1]} columns\")\n",
        "\n",
        "            # Show file info\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Total Rows\", df.shape[0])\n",
        "            with col2:\n",
        "                st.metric(\"Total Columns\", df.shape[1])\n",
        "            with col3:\n",
        "                matching_features = len([col for col in df.columns if col in selected_features])\n",
        "                st.metric(\"Matching Features\", f\"{matching_features}/{len(selected_features)}\")\n",
        "\n",
        "            # Show preview\n",
        "            st.markdown(\"**Data Preview:**\")\n",
        "            st.dataframe(df.head(10), use_container_width=True)\n",
        "\n",
        "            # Batch size selection\n",
        "            batch_size = st.number_input(\"Batch Size for Processing\", min_value=100, max_value=1000, value=500, step=100)\n",
        "\n",
        "            # Prediction button\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "            with col1:\n",
        "                if st.button(\"üîÆ **PREDICT PATHOGENICITY FOR ALL MUTATIONS**\", type=\"primary\", use_container_width=True):\n",
        "                    with st.spinner(\"Making predictions...\"):\n",
        "                        predictions, probabilities = make_batch_predictions(\n",
        "                            df, model, selected_features, label_encoders, feature_modes, batch_size\n",
        "                        )\n",
        "                        if predictions:\n",
        "                            display_batch_results(df, predictions, probabilities)\n",
        "\n",
        "            with col2:\n",
        "                if st.button(\"üìã Show Required Columns\", use_container_width=True):\n",
        "                    show_required_columns(selected_features, df.columns)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Error processing file: {e}\")\n",
        "            st.info(\"Ensure your CSV is properly formatted with correct column names and data types.\")\n",
        "\n",
        "def show_required_columns(selected_features, uploaded_columns):\n",
        "    \"\"\"Show required columns vs uploaded columns\"\"\"\n",
        "    st.markdown(\"### Column Comparison\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"**Available in your CSV:**\")\n",
        "        available = [col for col in uploaded_columns if col in selected_features]\n",
        "        for col in available[:20]:\n",
        "            st.write(f\"‚úÖ {col}\")\n",
        "        if len(available) > 20:\n",
        "            st.write(f\"... and {len(available) - 20} more\")\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"**Missing (will use defaults):**\")\n",
        "        missing = [col for col in selected_features if col not in uploaded_columns]\n",
        "        for col in missing[:20]:\n",
        "            st.write(f\"‚ö†Ô∏è {col}\")\n",
        "        if len(missing) > 20:\n",
        "            st.write(f\"... and {len(missing) - 20} more\")\n",
        "\n",
        "def display_batch_results(original_df, predictions, probabilities):\n",
        "    \"\"\"Display batch prediction results\"\"\"\n",
        "    results_df = original_df.copy()\n",
        "    results_df['Predicted_Pathogenicity'] = predictions\n",
        "    results_df['Pathogenic_Probability'] = [f\"{p:.3f}\" for p in probabilities]\n",
        "    results_df['Confidence_Level'] = ['High' if p > 0.8 or p < 0.2 else 'Medium' if p > 0.6 or p < 0.4 else 'Low'\n",
        "                                     for p in probabilities]\n",
        "\n",
        "    st.markdown(\"## üéØ Prediction Results\")\n",
        "\n",
        "    pathogenic_count = sum(1 for p in predictions if p == 'Pathogenic')\n",
        "    benign_count = len(predictions) - pathogenic_count\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    with col1:\n",
        "        st.metric(\"Total Predictions\", len(predictions))\n",
        "    with col2:\n",
        "        st.metric(\"üî¥ Pathogenic\", pathogenic_count, f\"{pathogenic_count/len(predictions)*100:.1f}%\")\n",
        "    with col3:\n",
        "        st.metric(\"üü¢ Benign\", benign_count, f\"{benign_count/len(predictions)*100:.1f}%\")\n",
        "    with col4:\n",
        "        high_conf = sum(1 for p in probabilities if p > 0.8 or p < 0.2)\n",
        "        st.metric(\"High Confidence\", high_conf, f\"{high_conf/len(predictions)*100:.1f}%\")\n",
        "\n",
        "    st.markdown(\"### Filter Results:\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        filter_prediction = st.selectbox(\"Filter by Prediction:\", [\"All\", \"Pathogenic\", \"Benign\"])\n",
        "    with col2:\n",
        "        filter_confidence = st.selectbox(\"Filter by Confidence:\", [\"All\", \"High\", \"Medium\", \"Low\"])\n",
        "\n",
        "    filtered_df = results_df.copy()\n",
        "    if filter_prediction != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df['Predicted_Pathogenicity'] == filter_prediction]\n",
        "    if filter_confidence != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df['Confidence_Level'] == filter_confidence]\n",
        "\n",
        "    st.markdown(f\"**Showing {len(filtered_df)} of {len(results_df)} predictions:**\")\n",
        "    st.dataframe(filtered_df, use_container_width=True)\n",
        "\n",
        "    st.markdown(\"### üì• Download Results:\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        csv_data = results_df.to_csv(index=False)\n",
        "        st.download_button(\n",
        "            label=\"üìÑ Download All Results (CSV)\",\n",
        "            data=csv_data,\n",
        "            file_name=f\"mutation_predictions_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "            mime=\"text/csv\",\n",
        "            use_container_width=True\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        pathogenic_only = results_df[results_df['Predicted_Pathogenicity'] == 'Pathogenic']\n",
        "        if len(pathogenic_only) > 0:\n",
        "            pathogenic_csv = pathogenic_only.to_csv(index=False)\n",
        "            st.download_button(\n",
        "                label=\"üî¥ Download Pathogenic Only (CSV)\",\n",
        "                data=pathogenic_csv,\n",
        "                file_name=f\"pathogenic_mutations_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "def csv_format_guide_page(selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Page explaining CSV format requirements\"\"\"\n",
        "    st.markdown('<h2 class=\"sub-header\">üìã CSV Format Guide</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"file-upload-info\">\n",
        "        <h4>üìÅ How to format your CSV file for gene mutation prediction:</h4>\n",
        "        <p>Your CSV file should contain gene mutation data with columns matching the model's expected features.\n",
        "        Missing columns will use default values.</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### üéØ **Quick Start: Download Sample CSV Template**\")\n",
        "\n",
        "    sample_data = create_sample_csv_data(selected_features, label_encoders, feature_modes)\n",
        "    sample_csv = pd.DataFrame(sample_data).to_csv(index=False)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.download_button(\n",
        "            label=\"üì• Download Sample CSV Template\",\n",
        "            data=sample_csv,\n",
        "            file_name=\"gene_mutation_template.csv\",\n",
        "            mime=\"text/csv\",\n",
        "            help=\"Download this template and fill it with your mutation data\"\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"üëÄ Preview Sample Data\"):\n",
        "            st.dataframe(pd.DataFrame(sample_data), use_container_width=True)\n",
        "\n",
        "    st.markdown(\"### üìä **Model Features by Category**\")\n",
        "\n",
        "    categories = {\n",
        "        \"üß¨ Basic Mutation Info\": [f for f in selected_features if any(x in f.lower() for x in ['mutation', 'allele', 'type', 'cpg'])],\n",
        "        \"üìç Genomic Position\": [f for f in selected_features if any(x in f.lower() for x in ['hg', 'start', 'end', 'cdna', 'exon'])],\n",
        "        \"üî¨ Protein Effects\": [f for f in selected_features if 'protein' in f.lower()],\n",
        "        \"üìä Prediction Scores\": [f for f in selected_features if any(x in f.lower() for x in ['sift', 'polyphen', 'provean', 'condel', 'mutassessor'])],\n",
        "        \"üè• Clinical Data\": [f for f in selected_features if any(x in f.lower() for x in ['disease', 'tumor', 'cancer', 'pathology', 'smoking'])],\n",
        "    }\n",
        "\n",
        "    for category, features in categories.items():\n",
        "        if features:\n",
        "            with st.expander(f\"{category} ({len(features)} features)\"):\n",
        "                for i, feature in enumerate(sorted(features), 1):\n",
        "                    st.write(f\"{i}. `{feature}`\")\n",
        "\n",
        "    st.markdown(\"### üí° **Tips for Best Results**\")\n",
        "    st.markdown(\"\"\"\n",
        "    - **Include as many relevant columns as possible** for better predictions\n",
        "    - **Use consistent column names** matching the features above\n",
        "    - **Handle missing values**: Use 'Unknown' or leave blank for categorical data\n",
        "    - **Ensure numeric columns** contain numbers, not text\n",
        "    - **Avoid special characters** in categorical values\n",
        "    \"\"\")\n",
        "\n",
        "def create_sample_csv_data(selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Create sample CSV data for download\"\"\"\n",
        "    num_samples = 3\n",
        "    sample_data = {}\n",
        "    log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "    for feature in selected_features:\n",
        "        if feature in label_encoders:\n",
        "            classes = list(label_encoders[feature].classes_)\n",
        "            sample_data[feature] = np.random.choice(classes, size=num_samples)\n",
        "        else:\n",
        "            mode_value = feature_modes.get(feature, 0)\n",
        "            if isinstance(mode_value, (int, float)):\n",
        "                values = np.random.uniform(low=max(0, mode_value - 1), high=mode_value + 1, size=num_samples)\n",
        "                if feature in log_transformed_columns:\n",
        "                    values = np.log1p(values)\n",
        "                sample_data[feature] = values\n",
        "            else:\n",
        "                sample_data[feature] = [mode_value] * num_samples\n",
        "\n",
        "    return sample_data\n",
        "\n",
        "def single_prediction_page(model, selected_features, label_encoders, feature_modes):\n",
        "    st.markdown('<h2 class=\"sub-header\">Single Mutation Prediction</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\"üß¨ Basic Info\", \"üìç Genomic Position\", \"üî¨ Protein Features\", \"üìä Scores & Predictions\", \"üè• Clinical Data\"])\n",
        "\n",
        "    user_input = {}\n",
        "\n",
        "    with tab1:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Basic Mutation Information**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            if 'Mutation_Type_y' in selected_features and 'Mutation_Type_y' in label_encoders:\n",
        "                user_input['Mutation_Type_y'] = st.selectbox(\"Mutation Type\", list(label_encoders['Mutation_Type_y'].classes_))\n",
        "            if 'Mutant_Allele_x' in selected_features and 'Mutant_Allele_x' in label_encoders:\n",
        "                user_input['Mutant_Allele_x'] = st.selectbox(\"Mutant Allele\", list(label_encoders['Mutant_Allele_x'].classes_))\n",
        "            if 'Type' in selected_features and 'Type' in label_encoders:\n",
        "                user_input['Type'] = st.selectbox(\"Variant Type\", list(label_encoders['Type'].classes_))\n",
        "\n",
        "        with col2:\n",
        "            if 'CpG_y' in selected_features and 'CpG_y' in label_encoders:\n",
        "                user_input['CpG_y'] = st.selectbox(\"CpG Site\", list(label_encoders['CpG_y'].classes_))\n",
        "            if 'Complexity' in selected_features and 'Complexity' in label_encoders:\n",
        "                user_input['Complexity'] = st.selectbox(\"Mutation Complexity\", list(label_encoders['Complexity'].classes_))\n",
        "            if 'Py_Py_Doublets' in selected_features:\n",
        "                user_input['Py_Py_Doublets'] = st.number_input(\"Py-Py Doublets\", min_value=0, max_value=10, value=0, step=1)\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab2:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Genomic Position & Coordinates**\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            if 'HG19_Start_x' in selected_features:\n",
        "                user_input['HG19_Start_x'] = st.number_input(\"HG19 Start Position\", min_value=1, value=17000000, step=1)\n",
        "            if 'HG19_End_x' in selected_features:\n",
        "                user_input['HG19_End_x'] = st.number_input(\"HG19 End Position\", min_value=1, value=17000001, step=1)\n",
        "\n",
        "        with col2:\n",
        "            if 'HG38_Start' in selected_features:\n",
        "                user_input['HG38_Start'] = st.number_input(\"HG38 Start Position\", min_value=1, value=7500000, step=1)\n",
        "            if 'HG38_End' in selected_features:\n",
        "                user_input['HG38_End'] = st.number_input(\"HG38 End Position\", min_value=1, value=7500001, step=1)\n",
        "\n",
        "        with col3:\n",
        "            if 'Start_cDNA_x' in selected_features:\n",
        "                user_input['Start_cDNA_x'] = st.number_input(\"cDNA Start\", min_value=1, value=100, step=1)\n",
        "            if 'End_cDNA_x' in selected_features:\n",
        "                user_input['End_cDNA_x'] = st.number_input(\"cDNA End\", min_value=1, value=101, step=1)\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab3:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Protein Isoform Effects**\")\n",
        "\n",
        "        protein_features = [f for f in selected_features if f.startswith('Protein')]\n",
        "\n",
        "        if protein_features:\n",
        "            st.markdown(\"**TP53 Protein Isoform Predictions:**\")\n",
        "            cols = st.columns(3)\n",
        "\n",
        "            for i, feature in enumerate(protein_features[:15]):\n",
        "                with cols[i % 3]:\n",
        "                    if feature in label_encoders:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            feature.replace('Protein ', '').replace('_', ' '),\n",
        "                            list(label_encoders[feature].classes_),\n",
        "                            key=f\"protein_{i}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            feature.replace('Protein ', '').replace('_', ' '),\n",
        "                            ['Neutral', 'Deleterious', 'Unknown'],\n",
        "                            key=f\"protein_{i}\"\n",
        "                        )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab4:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Prediction Scores & Tools**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            if 'Sift Score' in selected_features:\n",
        "                user_input['Sift Score'] = st.slider(\"SIFT Score\", 0.0, 1.0, 0.5, step=0.01)\n",
        "            if 'Sift Prediction' in selected_features and 'Sift Prediction' in label_encoders:\n",
        "                user_input['Sift Prediction'] = st.selectbox(\"SIFT Prediction\", list(label_encoders['Sift Prediction'].classes_))\n",
        "            if 'Polyphen' in selected_features and 'Polyphen' in label_encoders:\n",
        "                user_input['Polyphen'] = st.selectbox(\"PolyPhen Prediction\", list(label_encoders['Polyphen'].classes_))\n",
        "            if 'Provean_Score_y' in selected_features:\n",
        "                user_input['Provean_Score_y'] = st.slider(\"PROVEAN Score\", -10.0, 10.0, -2.5, step=0.1)\n",
        "\n",
        "        with col2:\n",
        "            if 'Mutassessor_score_y' in selected_features:\n",
        "                user_input['Mutassessor_score_y'] = st.slider(\"MutationAssessor Score\", 0.0, 5.0, 2.5, step=0.1)\n",
        "            if 'Condel_y' in selected_features:\n",
        "                user_input['Condel_y'] = st.slider(\"Condel Score\", 0.0, 1.0, 0.5, step=0.01)\n",
        "            if 'MutPred_Splice_General_Score_y' in selected_features:\n",
        "                user_input['MutPred_Splice_General_Score_y'] = st.slider(\"MutPred Splice Score\", 0.0, 1.0, 0.5, step=0.01)\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab5:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Clinical & Environmental Data**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            if 'Disease' in selected_features and 'Disease' in label_encoders:\n",
        "                user_input['Disease'] = st.selectbox(\"Associated Disease\", list(label_encoders['Disease'].classes_))\n",
        "            if 'Sample_pathology' in selected_features and 'Sample_pathology' in label_encoders:\n",
        "                user_input['Sample_pathology'] = st.selectbox(\"Sample Pathology\", list(label_encoders['Sample_pathology'].classes_))\n",
        "            if 'Smoking' in selected_features and 'Smoking' in label_encoders:\n",
        "                user_input['Smoking'] = st.selectbox(\"Smoking History\", list(label_encoders['Smoking'].classes_))\n",
        "\n",
        "        with col2:\n",
        "            if 'Tumor_Stat' in selected_features and 'Tumor_Stat' in label_encoders:\n",
        "                user_input['Tumor_Stat'] = st.selectbox(\"Tumor Status\", list(label_encoders['Tumor_Stat'].classes_))\n",
        "            if 'Germline_Stat' in selected_features and 'Germline_Stat' in label_encoders:\n",
        "                user_input['Germline_Stat'] = st.selectbox(\"Germline Status\", list(label_encoders['Germline_Stat'].classes_))\n",
        "            if 'Exposure' in selected_features and 'Exposure' in label_encoders:\n",
        "                user_input['Exposure'] = st.selectbox(\"Environmental Exposure\", list(label_encoders['Exposure'].classes_))\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    for feature in selected_features:\n",
        "        if feature not in user_input:\n",
        "            if feature in feature_modes:\n",
        "                user_input[feature] = feature_modes[feature]\n",
        "            else:\n",
        "                user_input[feature] = 0.0\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"üîÆ Predict Pathogenicity\", type=\"primary\", use_container_width=True):\n",
        "        prediction, probability = make_prediction(user_input, model, selected_features, label_encoders, feature_modes)\n",
        "        display_prediction_result(prediction, probability)\n",
        "\n",
        "def batch_prediction_page(model, selected_features, label_encoders, feature_modes):\n",
        "    st.markdown('<h2 class=\"sub-header\">Advanced Batch Mutation Prediction</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"Upload a CSV file with mutation data for batch prediction with advanced options.\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            st.success(f\"File uploaded successfully! Shape: {df.shape}\")\n",
        "\n",
        "            st.markdown(\"**Preview of uploaded data:**\")\n",
        "            st.dataframe(df.head())\n",
        "\n",
        "            batch_size = st.slider(\"Batch Size for Processing\", min_value=100, max_value=1000, value=500, step=100)\n",
        "\n",
        "            if st.button(\"üöÄ Run Batch Prediction\", type=\"primary\"):\n",
        "                predictions, probabilities = make_batch_predictions(\n",
        "                    df, model, selected_features, label_encoders, feature_modes, batch_size\n",
        "                )\n",
        "\n",
        "                results_df = df.copy()\n",
        "                results_df['Predicted_Pathogenicity'] = predictions\n",
        "                results_df['Pathogenic_Probability'] = [f\"{p:.4f}\" for p in probabilities]\n",
        "\n",
        "                st.markdown(\"**Prediction Results:**\")\n",
        "                st.dataframe(results_df, use_container_width=True)\n",
        "\n",
        "                csv = results_df.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download Results as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=\"mutation_predictions.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "                st.markdown(\"**Prediction Summary:**\")\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    st.metric(\"Total Predictions\", len(predictions))\n",
        "                with col2:\n",
        "                    st.metric(\"Pathogenic\", sum(1 for p in predictions if p == 'Pathogenic'))\n",
        "                with col3:\n",
        "                    st.metric(\"Benign\", sum(1 for p in predictions if p == 'Benign'))\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing file: {e}\")\n",
        "            st.info(\"Please check that your CSV file contains valid data and correct column names.\")\n",
        "\n",
        "def feature_information_page(selected_features):\n",
        "    st.markdown('<h2 class=\"sub-header\">Feature Information</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"This page provides information about the 100 features used in the model.\")\n",
        "\n",
        "    categories = {\n",
        "        \"Genomic Position\": [f for f in selected_features if any(x in f.lower() for x in ['hg', 'start', 'end', 'cdna', 'exon'])],\n",
        "        \"Protein Effects\": [f for f in selected_features if 'protein' in f.lower()],\n",
        "        \"Prediction Scores\": [f for f in selected_features if any(x in f.lower() for x in ['sift', 'polyphen', 'provean', 'condel', 'mutassessor'])],\n",
        "        \"Mutation Details\": [f for f in selected_features if any(x in f.lower() for x in ['mutation', 'allele', 'codon', 'variant'])],\n",
        "        \"Clinical Data\": [f for f in selected_features if any(x in f.lower() for x in ['disease', 'tumor', 'cancer', 'pathology', 'smoking'])],\n",
        "        \"Other Features\": []\n",
        "    }\n",
        "\n",
        "    categorized = set()\n",
        "    for cat_features in categories.values():\n",
        "        categorized.update(cat_features)\n",
        "\n",
        "    categories[\"Other Features\"] = [f for f in selected_features if f not in categorized]\n",
        "\n",
        "    for category, features in categories.items():\n",
        "        if features:\n",
        "            with st.expander(f\"{category} ({len(features)} features)\"):\n",
        "                for feature in sorted(features):\n",
        "                    st.write(f\"‚Ä¢ {feature}\")\n",
        "\n",
        "def preprocess_input(user_input, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Preprocess user input to match model expectations\"\"\"\n",
        "    processed_input = {}\n",
        "    log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "    for feature in selected_features:\n",
        "        if feature in user_input:\n",
        "            value = user_input[feature]\n",
        "\n",
        "            if feature in label_encoders:\n",
        "                try:\n",
        "                    if isinstance(value, str):\n",
        "                        processed_input[feature] = label_encoders[feature].transform([value])[0]\n",
        "                    else:\n",
        "                        processed_input[feature] = value\n",
        "                except Exception:\n",
        "                    processed_input[feature] = label_encoders[feature].transform([label_encoders[feature].classes_[0]])[0]\n",
        "                    st.warning(f\"Invalid value for {feature}: {value}. Using default encoded value.\")\n",
        "            else:\n",
        "                if feature in log_transformed_columns and isinstance(value, (int, float)):\n",
        "                    processed_input[feature] = np.log1p(value)\n",
        "                else:\n",
        "                    processed_input[feature] = value\n",
        "        else:\n",
        "            default_value = feature_modes.get(feature, 0.0)\n",
        "            if feature in log_transformed_columns and isinstance(default_value, (int, float)):\n",
        "                processed_input[feature] = np.log1p(default_value)\n",
        "            else:\n",
        "                processed_input[feature] = default_value\n",
        "\n",
        "    return processed_input\n",
        "\n",
        "def make_prediction(user_input, model, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Make a single prediction\"\"\"\n",
        "    try:\n",
        "        processed_input = preprocess_input(user_input, selected_features, label_encoders, feature_modes)\n",
        "\n",
        "        input_df = pd.DataFrame([processed_input])\n",
        "        input_df = input_df[selected_features]\n",
        "\n",
        "        prediction_proba = model.predict_proba(input_df)[0]\n",
        "        prediction = model.predict(input_df)[0]\n",
        "\n",
        "        pred_label = 'Pathogenic' if prediction == 1 else 'Benign'\n",
        "        confidence = float(max(prediction_proba))\n",
        "\n",
        "        return pred_label, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error making prediction: {str(e)}\")\n",
        "        st.error(\"Please check input data format and try again.\")\n",
        "        return None, 0.0\n",
        "\n",
        "def make_batch_predictions(df, model, selected_features, label_encoders, feature_modes, batch_size=500):\n",
        "    \"\"\"Make batch predictions\"\"\"\n",
        "    errors = []\n",
        "    try:\n",
        "        input_df = df.copy()\n",
        "        log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "        for feature in selected_features:\n",
        "            if feature not in input_df.columns:\n",
        "                input_df[feature] = feature_modes.get(feature, 0)\n",
        "\n",
        "        for feature in selected_features:\n",
        "            if feature in input_df.columns:\n",
        "                if feature in label_encoders:\n",
        "                    try:\n",
        "                        input_df[feature] = input_df[feature].fillna('Unknown').astype(str)\n",
        "                        encoder_classes = [str(c) for c in label_encoders[feature].classes_]\n",
        "                        def safe_transform(value):\n",
        "                            value = str(value).strip()\n",
        "                            return label_encoders[feature].transform([value])[0] if value in encoder_classes else label_encoders[feature].transform([encoder_classes[0]])[0]\n",
        "                        input_df[feature] = input_df[feature].apply(safe_transform)\n",
        "                    except Exception as enc_error:\n",
        "                        errors.append(f\"Error encoding feature {feature}: {str(enc_error)}\")\n",
        "                        input_df[feature] = feature_modes.get(feature, 0)\n",
        "                elif feature in log_transformed_columns:\n",
        "                    input_df[feature] = pd.to_numeric(input_df[feature], errors='coerce').abs().fillna(0)\n",
        "                    input_df[feature] = np.log1p(input_df[feature])\n",
        "\n",
        "        all_predictions = []\n",
        "        all_probabilities = []\n",
        "        progress_bar = st.progress(0)\n",
        "        total_batches = (len(input_df) + batch_size - 1) // batch_size\n",
        "\n",
        "        for i in range(0, len(input_df), batch_size):\n",
        "            batch_df = input_df.iloc[i:i+batch_size][selected_features]\n",
        "            batch_df = batch_df.fillna(0)\n",
        "            predictions = model.predict(batch_df)\n",
        "            probabilities = model.predict_proba(batch_df)\n",
        "            all_predictions.extend(['Pathogenic' if p == 1 else 'Benign' for p in predictions])\n",
        "            all_probabilities.extend(probabilities[:, 1] if probabilities.shape[1] >= 2 else probabilities[:, 0])\n",
        "            progress_bar.progress(min((i + batch_size) / len(input_df), 1.0))\n",
        "\n",
        "        progress_bar.empty()\n",
        "\n",
        "        if errors:\n",
        "            with open('prediction_errors.txt', 'w') as f:\n",
        "                f.write(\"\\n\".join(errors))\n",
        "            st.markdown(\"### Download Error Log\")\n",
        "            st.download_button(\n",
        "                label=\"üìã Download Error Log\",\n",
        "                data=open('prediction_errors.txt', 'rb'),\n",
        "                file_name=\"prediction_errors.txt\",\n",
        "                mime=\"text/plain\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "        return all_predictions, all_probabilities\n",
        "\n",
        "    except Exception as e:\n",
        "        errors.append(str(e))\n",
        "        with open('prediction_errors.txt', 'w') as f:\n",
        "            f.write(\"\\n\".join(errors))\n",
        "        st.error(f\"Error in batch predictions: {str(e)}\")\n",
        "        st.error(\"Check your CSV for valid data (correct columns, data types).\")\n",
        "        st.download_button(\n",
        "            label=\"üìã Download Error Log\",\n",
        "            data=open('prediction_errors.txt', 'rb'),\n",
        "            file_name=\"prediction_errors.txt\",\n",
        "            mime=\"text/plain\"\n",
        "        )\n",
        "        return [], []\n",
        "\n",
        "def display_prediction_result(prediction, probability):\n",
        "    \"\"\"Display prediction result with styling\"\"\"\n",
        "    if prediction is None:\n",
        "        st.error(\"Prediction failed. Please check your input data.\")\n",
        "        return\n",
        "\n",
        "    if prediction == \"Pathogenic\":\n",
        "        st.markdown(f'''\n",
        "        <div class=\"prediction-result pathogenic\">\n",
        "            <strong>‚ö†Ô∏è PATHOGENIC</strong><br>\n",
        "            Confidence: {probability:.2%}\n",
        "        </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "        st.warning(\"‚ö†Ô∏è This mutation is predicted to be **PATHOGENIC**. Consider further clinical evaluation.\")\n",
        "\n",
        "    elif prediction == \"Benign\":\n",
        "        st.markdown(f'''\n",
        "        <div class=\"prediction-result benign\">\n",
        "            <strong>‚úîÔ∏è BENIGN</strong><br>\n",
        "            Confidence: {probability:.2%}\n",
        "        </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "        st.success(\"‚úîÔ∏è This mutation is predicted to be **BENIGN**. Low likelihood of pathogenicity.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "F2CC6wCJwBYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7751c5-f04c-49f1-f8ad-8dae000de0be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "!streamlit run app.py & sleep 5 && npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "_pOUn6rWwHp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d24811-2002-44c2-d6da-f46f6ef77fbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.9.113.65\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.9.113.65:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0Kyour url is: https://lovely-pots-matter.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}